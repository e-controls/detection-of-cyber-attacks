{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheusfigueiredoo/detection-of-cyber-attacks/blob/main/binary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3fbd576",
      "metadata": {
        "id": "e3fbd576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4821f360-c98b-4352-dac3-802d0b166fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m1.6/1.7 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.12.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install keras==2.12.0\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef16d64",
      "metadata": {
        "id": "4ef16d64"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"drive/MyDrive/MQTTset/train70_augmented.csv\")\n",
        "test = pd.read_csv(\"drive/MyDrive/MQTTset/test30_augmented.csv\")\n",
        "train = pd.DataFrame(train)\n",
        "test = pd.DataFrame(test)\n",
        "\n",
        "# distribuição das targets\n",
        "print(train['target'].value_counts())\n",
        "print(test['target'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f6bb86-474b-453b-96e2-3a564a94d2ca",
      "metadata": {
        "id": "64f6bb86-474b-453b-96e2-3a564a94d2ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e45737b-8270-406e-ea78-091ff31ffdc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "bruteforce    1400000\n",
            "flood         1400000\n",
            "slowite       1400000\n",
            "dos           1400000\n",
            "malformed     1400000\n",
            "legitimate    1400000\n",
            "Name: count, dtype: int64\n",
            "target\n",
            "legitimate    2999999\n",
            "dos            600000\n",
            "slowite        600000\n",
            "flood          600000\n",
            "bruteforce     600000\n",
            "malformed      600000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# balanceamento dos dados\n",
        "\n",
        "# dados de treinamento\n",
        "for i in train.index:\n",
        "    if train['target'][i] != 'legitimate':\n",
        "        train.at[i, 'target'] = 'malicious'\n",
        "\n",
        "# dados de teste\n",
        "for i in test.index:\n",
        "    if test['target'][i] != 'legitimate':\n",
        "        test.at[i, 'target'] = 'malicious'\n",
        "\n",
        "# nova distribuição de dados\n",
        "print(train['target'].value_counts())\n",
        "print(test['target'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3df84781",
      "metadata": {
        "id": "3df84781"
      },
      "outputs": [],
      "source": [
        "# pre processamento de dados\n",
        "# separacao de features e targets\n",
        "\n",
        "X_train = train.iloc[:,:-1]\n",
        "y_train = train['target']\n",
        "X_test = test.iloc[:,:-1]\n",
        "y_test = test.iloc[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94ba6123",
      "metadata": {
        "id": "94ba6123"
      },
      "outputs": [],
      "source": [
        "# transformacao de features e targets categoricas em numeros inteiros\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label = LabelEncoder()\n",
        "\n",
        "# targets\n",
        "label.fit(y_train)\n",
        "label.fit(y_test)\n",
        "\n",
        "label.classes_     # ordem das classes\n",
        "print(y_train)\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = label.transform(y_train)\n",
        "y_test = label.transform(y_test)\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "metadata": {
        "id": "2H-Av3ZcilW9"
      },
      "id": "2H-Av3ZcilW9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features\n",
        "X_train['tcp.flags'] = label.fit_transform(X_train['tcp.flags'])\n",
        "X_train['mqtt.conack.flags'] = label.fit_transform(X_train['mqtt.conack.flags'])\n",
        "X_train['mqtt.hdrflags'] = label.fit_transform(X_train['mqtt.hdrflags'])\n",
        "X_train['mqtt.protoname'] = label.fit_transform(X_train['mqtt.protoname'])\n",
        "X_train['mqtt.msg'] = label.fit_transform(X_train['mqtt.msg'])\n",
        "X_train['mqtt.conflags'] = label.fit_transform(X_train['mqtt.conflags'])\n",
        "\n",
        "X_test['tcp.flags'] = label.fit_transform(X_test['tcp.flags'])\n",
        "X_test['mqtt.conack.flags'] = label.fit_transform(X_test['mqtt.conack.flags'])\n",
        "X_test['mqtt.hdrflags'] = label.fit_transform(X_test['mqtt.hdrflags'])\n",
        "X_test['mqtt.protoname'] = label.fit_transform(X_test['mqtt.protoname'])\n",
        "X_test['mqtt.msg'] = label.fit_transform(X_test['mqtt.msg'])\n",
        "X_test['mqtt.conflags'] = label.fit_transform(X_test['mqtt.conflags'])"
      ],
      "metadata": {
        "id": "2afuT_CcUNNj"
      },
      "id": "2afuT_CcUNNj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "505c10f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "505c10f4",
        "outputId": "4c620b31-7a9b-46f6-e8e8-9ebb7e38a946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85500000, 20)\n",
            "(28500000, 20)\n"
          ]
        }
      ],
      "source": [
        "# ajuste de dados\n",
        "# columns_0 são as colunas com dados iguais a 0\n",
        "\n",
        "columns_0 = ['mqtt.conack.flags.reserved', 'mqtt.conack.flags.sp', 'mqtt.conflag.qos',\n",
        "           'mqtt.conflag.reserved', 'mqtt.conflag.retain', 'mqtt.conflag.willflag',\n",
        "           'mqtt.retain', 'mqtt.sub.qos', 'mqtt.suback.qos', 'mqtt.willmsg', 'mqtt.willmsg_len',\n",
        "           'mqtt.willtopic', 'mqtt.willtopic_len']\n",
        "X_train = X_train.drop(columns_0, axis=1)\n",
        "X_test = X_test.drop(columns_0, axis=1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c216e6ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c216e6ce",
        "outputId": "b55c8177-bbe3-4456-9573-b8b1d0760a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "\n",
        "print(type(X_train))\n",
        "print(type(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# treinamento de dados\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "XEGe2yi2kmHe"
      },
      "id": "XEGe2yi2kmHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b26c2a9c",
      "metadata": {
        "id": "b26c2a9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c779f3-909c-4cda-d45d-c187bb392351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.8798754736842105\n",
            "Accuracy test: 0.8799122456140351\n"
          ]
        }
      ],
      "source": [
        "# decision tree\n",
        "\n",
        "tree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None)\n",
        "tree.fit(X_train, y_train)\n",
        "print(\"Accuracy train: \", tree.score(X_train, y_train))\n",
        "print(\"Accuracy test: \", tree.score(X_test, y_test), \"\\n\")\n",
        "\n",
        "# predição de valores\n",
        "predict_tree = tree.predict(X_test)\n",
        "print(\"Tabela de desempenho: \")\n",
        "print(classification_report(y_test, predict_tree), \"\\n\")\n",
        "\n",
        "# confusion matrix\n",
        "matrix_tree = confusion_matrix(y_test, predict_tree)\n",
        "print(matrix_tree, \"\\n\")\n",
        "cm_tree = confusion_matrix(y_test, predict_tree, labels=tree.classes_)\n",
        "disp_tree = ConfusionMatrixDisplay(confusion_matrix=cm_tree, display_labels=tree.classes_)\n",
        "disp_tree.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random forest\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"Accuracy train: \", rf.score(X_train, y_train))\n",
        "print(\"Accuracy test: \", rf.score(X_test, y_test), \"\\n\")\n",
        "\n",
        "# predição de valores\n",
        "predict_rf = rf.predict(X_test)\n",
        "print(\"Tabela de desempenho: \")\n",
        "print(classification_report(y_test, predict_rf), \"\\n\")\n",
        "\n",
        "# confusion matrix\n",
        "matrix_rf = confusion_matrix(y_test, predict_rf)\n",
        "print(matrix_rf, \"\\n\")\n",
        "cm_rf = confusion_matrix(y_test, predict_rf, labels=rf.classes_)\n",
        "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rf.classes_)\n",
        "disp_rf.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rziYCu3Fjndb"
      },
      "id": "rziYCu3Fjndb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# naive bayes\n",
        "\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "print(\"Accuracy train: \", nb.score(X_train, y_train))\n",
        "print(\"Accuracy test: \", nb.score(X_test, y_test), \"\\n\")\n",
        "\n",
        "# predição de valores\n",
        "predict_nb = nb.predict(X_test)\n",
        "print(\"Tabela de desempenho: \")\n",
        "print(classification_report(y_test, predict_nb), \"\\n\")\n",
        "\n",
        "# confusion matrix\n",
        "matrix_nb = confusion_matrix(y_test, predict_nb)\n",
        "print(matrix_nb, \"\\n\")\n",
        "cm_nb = confusion_matrix(y_test, predict_nb, labels=nb.classes_)\n",
        "disp_nb = ConfusionMatrixDisplay(confusion_matrix=cm_nb, display_labels=nb.classes_)\n",
        "disp_nb.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gr7TIBhUzLgT"
      },
      "id": "gr7TIBhUzLgT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient boosting\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "print(\"Accuracy train: \", gb.score(X_train, y_train))\n",
        "print(\"Accuracy test: \", gb.score(X_test, y_test), \"\\n\")\n",
        "\n",
        "# predição de valores\n",
        "predict_gb = gb.predict(X_test)\n",
        "print(\"Tabela de desempenho: \")\n",
        "print(classification_report(y_test, predict_gb), \"\\n\")\n",
        "\n",
        "# confusion matrix\n",
        "matrix_gb = confusion_matrix(y_test, predict_gb)\n",
        "print(matrix_gb, \"\\n\")\n",
        "cm_gb = confusion_matrix(y_test, predict_gb, labels=gb.classes_)\n",
        "disp_gb = ConfusionMatrixDisplay(confusion_matrix=cm_gb, display_labels=gb.classes_)\n",
        "disp_gb.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sko-E4WYz2sI"
      },
      "id": "sko-E4WYz2sI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-layer perceptron\n",
        "\n",
        "mlp = MLPClassifier(solver='adam', shuffle=True, random_state=0, alpha=0.0000001)\n",
        "mlp.fit(X_train, y_train)\n",
        "print(\"Accuracy train: \", mlp.score(X_train, y_train))\n",
        "print(\"Accuracy test: \", mlp.score(X_test, y_test), \"\\n\")\n",
        "\n",
        "# predição de valores\n",
        "predict_mlp = mlp.predict(X_test)\n",
        "print(\"Tabela de desempenho: \")\n",
        "print(classification_report(y_test, predict_mlp), \"\\n\")\n",
        "\n",
        "# confusion matrix\n",
        "matrix_mlp = confusion_matrix(y_test, predict_mlp)\n",
        "print(matrix_mlp, \"\\n\")\n",
        "cm_mlp = confusion_matrix(y_test, predict_mlp, labels=mlp.classes_)\n",
        "disp_mlp = ConfusionMatrixDisplay(confusion_matrix=cm_mlp, display_labels=mlp.classes_)\n",
        "disp_mlp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TVcXQrh80kaK"
      },
      "id": "TVcXQrh80kaK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sequential neural network\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(50, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(30, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(20, kernel_initializer='normal'))\n",
        "model.add(Dense(6,activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
        "history = model.fit(X_train,y_train,validation_data=(X_test,y_test),callbacks=[monitor],verbose=2,epochs=200,batch_size=1000)\n",
        "\n",
        "# matriz de confusão\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(conf_matrix, \"\\n\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Classe ' + str(i) for i in range(conf_matrix.shape[0])],\n",
        "            yticklabels=['Classe ' + str(i) for i in range(conf_matrix.shape[0])])\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# valores de perda e acurácia durante o treinamento\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# curvas de perda\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss, label='Perda no Treinamento', color='blue')\n",
        "plt.plot(val_loss, label='Perda na Validação', color='red')\n",
        "plt.title('Curvas de Perda durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "print(\"\\n\")\n",
        "\n",
        "# curvas de acurácia\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracy, label='Acurácia no Treinamento', color='blue')\n",
        "plt.plot(val_accuracy, label='Acurácia na Validação', color='red')\n",
        "plt.title('Curvas de Acurácia durante o Treinamento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-1nM0iUtqsul"
      },
      "id": "-1nM0iUtqsul",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}